"""
Google Gemini AI modÃ¼lÃ¼ - Agentic Approach
Bu modÃ¼l Google Gemini'yi agent olarak kullanÄ±r, kendi kararlarÄ±nÄ± verir.
"""

import google.generativeai as genai
from typing import List, Dict, Any, Callable
from config import Config

class AgenticGeminiChatbot:
    """Agentic Google Gemini chatbot sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        """Gemini API'yi yapÄ±landÄ±r"""
        genai.configure(api_key=Config.GOOGLE_API_KEY)
        self.model = genai.GenerativeModel('gemini-2.5-flash') #flash
        
        # AraÃ§larÄ± sakla
        self.available_tools = {}
        print("âœ… Agentic Google Gemini modeli baÅŸlatÄ±ldÄ±")
    
    def register_tool(self, name: str, func: Callable, description: str):
        """
        Gemini'nin kullanabileceÄŸi araÃ§larÄ± kaydet
        
        Args:
            name: AraÃ§ adÄ±
            func: Ã‡aÄŸrÄ±lacak fonksiyon
            description: AracÄ±n aÃ§Ä±klamasÄ±
        """
        self.available_tools[name] = {
            'function': func,
            'description': description
        }
        print(f"ğŸ”§ AraÃ§ kaydedildi: {name}")
    
    def decide_and_respond(self, query: str) -> str:
        """
        KullanÄ±cÄ± sorusuna gÃ¶re hangi araÃ§larÄ± kullanacaÄŸÄ±na karar verir ve yanÄ±t oluÅŸturur
        
        Args:
            query: KullanÄ±cÄ± sorusu
            
        Returns:
            Final yanÄ±t
        """
        try:
            # Ä°lk karar verme promptu
            decision_prompt = self._create_decision_prompt(query)
            
            # Model karar veriyor - debug print kaldÄ±rÄ±ldÄ±
            decision_response = self.model.generate_content(decision_prompt)
            
            if not decision_response.text:
                return "ÃœzgÃ¼nÃ¼m, karar veremiyorum."
            
            decision = decision_response.text.strip()
            # Model kararÄ± debug print kaldÄ±rÄ±ldÄ±
            
            # Karara gÃ¶re araÃ§larÄ± kullan ve bilgi topla
            context_data = self._execute_decision(decision, query)
            
            # Final yanÄ±t oluÅŸtur
            final_response = self._generate_final_response(query, context_data, decision)
            
            return final_response
            
        except Exception as e:
            print(f"âŒ Agentic yanÄ±t hatasÄ±: {e}")
            return f"Hata oluÅŸtu: {str(e)}"
    
    def decide_and_respond_stream(self, query: str):
        """
        Streaming versiyonu
        """
        try:
            # Ä°lk karar verme
            decision_prompt = self._create_decision_prompt(query)
            
            # Model karar veriyor - debug print kaldÄ±rÄ±ldÄ±
            decision_response = self.model.generate_content(decision_prompt)
            
            if not decision_response.text:
                yield "ÃœzgÃ¼nÃ¼m, karar veremiyorum."
                return
            
            decision = decision_response.text.strip()
            # Model kararÄ± debug print kaldÄ±rÄ±ldÄ±
            
            # Karara gÃ¶re araÃ§larÄ± kullan
            context_data = self._execute_decision(decision, query)
            
            # Streaming final yanÄ±t
            final_prompt = self._create_final_prompt(query, context_data, decision)
            
            response = self.model.generate_content(final_prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    yield chunk.text
                    
        except Exception as e:
            print(f"âŒ Agentic streaming hatasÄ±: {e}")
            yield f"Hata oluÅŸtu: {str(e)}"
    
    def _create_decision_prompt(self, query: str) -> str:
        """Karar verme promptu oluÅŸtur"""
        tools_description = "\n".join([
            f"- {name}: {info['description']}" 
            for name, info in self.available_tools.items()
        ])
        
        prompt = f"""Sen bir akÄ±llÄ± asistansÄ±n. KullanÄ±cÄ±nÄ±n sorusuna en iyi ÅŸekilde yanÄ±t verebilmek iÃ§in hangi kaynaklarÄ± kullanman gerektiÄŸine karar ver.

MEVCUT ARAÃ‡LAR:
{tools_description}

KULLANICI SORUSU: {query}

KARAR VER: YukarÄ±daki soruya yanÄ±t verebilmek iÃ§in hangi araÃ§larÄ± kullanman gerekiyor? 

Sadece ÅŸu formatlardan birini kullan:
- "TRANSCRIPT_ONLY" - Sadece ders notlarÄ±/transcript gerekli
- "BOOK_ONLY" - Sadece kitap bilgisi gerekli  
- "BOTH_SOURCES" - Her iki kaynak da gerekli
- "NO_SEARCH" - Genel bilgi, arama gerekmez

KararÄ±nÄ± tek kelime olarak ver, aÃ§Ä±klama yapma."""

        return prompt
    
    def _execute_decision(self, decision: str, query: str) -> Dict[str, Any]:
        """Karara gÃ¶re araÃ§larÄ± Ã§alÄ±ÅŸtÄ±r"""
        context_data = {
            'transcript_docs': [],
            'book_docs': [],
            'source_info': '',
            'query': query
        }
        
        decision = decision.upper().strip()
        
        if 'TRANSCRIPT_ONLY' in decision:
            if 'search_transcript' in self.available_tools:
                result = self.available_tools['search_transcript']['function'](query)
                context_data['transcript_docs'] = result.get('documents', [])
                context_data['source_info'] = 'Ders Ä°Ã§eriÄŸi (model kararÄ±)'
                # Debug print kaldÄ±rÄ±ldÄ±
        
        elif 'BOOK_ONLY' in decision:
            if 'search_book' in self.available_tools:
                result = self.available_tools['search_book']['function'](query)
                context_data['book_docs'] = result.get('documents', [])
                context_data['source_info'] = 'Kitap (model kararÄ±)'
                # Debug print kaldÄ±rÄ±ldÄ±
        
        elif 'BOTH_SOURCES' in decision:
            if 'search_transcript' in self.available_tools:
                result = self.available_tools['search_transcript']['function'](query)
                context_data['transcript_docs'] = result.get('documents', [])
            
            if 'search_book' in self.available_tools:
                result = self.available_tools['search_book']['function'](query)
                context_data['book_docs'] = result.get('documents', [])
            
            context_data['source_info'] = 'Ders Ä°Ã§eriÄŸi + Kitap (model kararÄ±)'
            # Debug print kaldÄ±rÄ±ldÄ±
        
        else:  # NO_SEARCH
            context_data['source_info'] = 'Genel bilgi (arama yok)'
            # Debug print kaldÄ±rÄ±ldÄ±
        
        return context_data
    
    def _generate_final_response(self, query: str, context_data: Dict[str, Any], decision: str) -> str:
        """Final yanÄ±t oluÅŸtur"""
        final_prompt = self._create_final_prompt(query, context_data, decision)
        response = self.model.generate_content(final_prompt)
        return response.text if response.text else "YanÄ±t oluÅŸturulamadÄ±."
    
    def _create_final_prompt(self, query: str, context_data: Dict[str, Any], decision: str) -> str:
        """Final yanÄ±t promptu"""
        
        all_docs = context_data['transcript_docs'] + context_data['book_docs']
        context_text = "\n\n".join(all_docs) if all_docs else ""
        
        if context_text:
            prompt = f"""Sen yardÄ±msever bir ders asistanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorusunu verilen baÄŸlam bilgileri kullanarak yanÄ±tla.

BAÄLAM BÄ°LGÄ°LERÄ°:
Kaynak: {context_data['source_info']}

{context_text}

KULLANICI SORUSU: {query}

Bu bilgileri kullanarak detaylÄ± ve yararlÄ± bir yanÄ±t ver. Ders iÃ§eriÄŸinden bahsederken "hocanÄ±n dersinde..." ÅŸeklinde ifade et. Hangi kaynaktan bilgi aldÄ±ÄŸÄ±nÄ± belirt."""
        
        else:
            prompt = f"""Sen yardÄ±msever bir asistansÄ±n. Genel bilginle kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tla.

KULLANICI SORUSU: {query}

Genel bilginle yardÄ±mcÄ± bir yanÄ±t ver."""
        
        return prompt
    
    def generate_response(self, query: str, context_documents: List[str], 
                         source_info: str = "") -> str:
        """
        Verilen sorgu ve baÄŸlam kullanarak yanÄ±t oluÅŸtur
        
        Args:
            query: KullanÄ±cÄ± sorusu
            context_documents: BaÄŸlam dÃ¶kÃ¼manlarÄ±
            source_info: Kaynak bilgisi (transcript/kitap)
            
        Returns:
            OluÅŸturulan yanÄ±t
        """
        try:
            # BaÄŸlam metni oluÅŸtur
            context = "\n\n".join(context_documents) if context_documents else ""
            
            # Prompt oluÅŸtur
            prompt = self._create_prompt(query, context, source_info)
            
            # YanÄ±t oluÅŸtur
            response = self.model.generate_content(prompt)
            
            return response.text if response.text else "ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸturamadÄ±m."
            
        except Exception as e:
            print(f"âŒ YanÄ±t oluÅŸturma hatasÄ±: {e}")
            return f"Hata oluÅŸtu: {str(e)}"
    
    def generate_response_stream(self, query: str, context_documents: List[str], 
                               source_info: str = ""):
        """
        Verilen sorgu ve baÄŸlam kullanarak streaming yanÄ±t oluÅŸtur
        
        Args:
            query: KullanÄ±cÄ± sorusu
            context_documents: BaÄŸlam dÃ¶kÃ¼manlarÄ±
            source_info: Kaynak bilgisi (transcript/kitap)
            
        Yields:
            YanÄ±t parÃ§alarÄ±
        """
        try:
            # BaÄŸlam metni oluÅŸtur
            context = "\n\n".join(context_documents) if context_documents else ""
            
            # Prompt oluÅŸtur
            prompt = self._create_prompt(query, context, source_info)
            
            # Streaming yanÄ±t oluÅŸtur
            response = self.model.generate_content(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    yield chunk.text
                    
        except Exception as e:
            print(f"âŒ Streaming yanÄ±t hatasÄ±: {e}")
            yield f"Hata oluÅŸtu: {str(e)}"
    
    def _create_prompt(self, query: str, context: str, source_info: str) -> str:
        """
        Chatbot iÃ§in prompt oluÅŸtur
        
        Args:
            query: KullanÄ±cÄ± sorusu
            context: BaÄŸlam metni
            source_info: Kaynak bilgisi
            
        Returns:
            OluÅŸturulan prompt
        """
        base_prompt = """Sen yardÄ±msever bir ders asistanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorularÄ±nÄ± mevcut baÄŸlam bilgileri kullanarak yanÄ±tlÄ±yorsun.

Ã–NEMLI KURALLAR:
1. Ders iÃ§eriÄŸi bilgisi daha Ã¶nceliklidir.
2. GerektiÄŸinde kitap bilgisini kullanabilirsin.
3. BaÄŸlam bilgilerinde yanÄ±t yoksa, kibarca bilmediÄŸini belirt.
4. YanÄ±tlarÄ±nÄ± TÃ¼rkÃ§e ver.
5. Hangi kaynaktan bilgi aldÄ±ÄŸÄ±nÄ± belirt.
6. Ä°nsanlara konuyu anlamalarÄ±nda yardÄ±mcÄ± ol. Bu esnada yorum yapman, Ã¶rnek vermen gerekiyorsa ver.
7. DoÄŸrudan ders metnini yazmak yerine bunu Ã¶ÄŸrencinin anlamasÄ± iÃ§in daha detaylÄ± anlat. Yorumla ve aÃ§Ä±kla.
8. Ders iÃ§eriÄŸinden bahsederken "hocanÄ±n dersinde..." ÅŸeklinde ifade et."""

        if context:
            source_text = f"\n\nKAYNAK: {source_info}" if source_info else ""
            prompt = f"""{base_prompt}

BAÄLAM BÄ°LGÄ°LERÄ°:{source_text}
{context}

KULLANICI SORUSU: {query}

YANITINIZ:"""
        else:
            prompt = f"""{base_prompt}

ÃœzgÃ¼nÃ¼m, bu konuda baÄŸlam bilgim bulunmuyor.

KULLANICI SORUSU: {query}

YANITINIZ:"""
        
        return prompt
